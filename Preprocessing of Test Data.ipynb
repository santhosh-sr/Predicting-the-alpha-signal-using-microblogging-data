{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the alpha signal using microblogging data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import emoji\n",
    "import copy\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_factors = pd.read_csv(\"test_factors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>SF1</th>\n",
       "      <th>SF2</th>\n",
       "      <th>SF3</th>\n",
       "      <th>SF4</th>\n",
       "      <th>SF5</th>\n",
       "      <th>SF6</th>\n",
       "      <th>SF7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270007</td>\n",
       "      <td>21/07/18</td>\n",
       "      <td>$INTC</td>\n",
       "      <td>-3.062194</td>\n",
       "      <td>1.223466</td>\n",
       "      <td>1.741714</td>\n",
       "      <td>2.279266</td>\n",
       "      <td>-1.323573</td>\n",
       "      <td>-0.274912</td>\n",
       "      <td>-4.504449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270008</td>\n",
       "      <td>05/10/18</td>\n",
       "      <td>$CTSH</td>\n",
       "      <td>0.816263</td>\n",
       "      <td>-2.184408</td>\n",
       "      <td>0.157975</td>\n",
       "      <td>-0.264743</td>\n",
       "      <td>-0.836282</td>\n",
       "      <td>0.046276</td>\n",
       "      <td>0.826353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270009</td>\n",
       "      <td>01/10/18</td>\n",
       "      <td>$CB</td>\n",
       "      <td>0.401281</td>\n",
       "      <td>0.091604</td>\n",
       "      <td>0.083411</td>\n",
       "      <td>-1.147041</td>\n",
       "      <td>-0.485223</td>\n",
       "      <td>-0.601060</td>\n",
       "      <td>1.012811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270010</td>\n",
       "      <td>24/10/18</td>\n",
       "      <td>$CTAS</td>\n",
       "      <td>-0.783521</td>\n",
       "      <td>1.192929</td>\n",
       "      <td>0.813831</td>\n",
       "      <td>-0.368166</td>\n",
       "      <td>-1.113656</td>\n",
       "      <td>-0.553581</td>\n",
       "      <td>-0.683803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270011</td>\n",
       "      <td>27/07/18</td>\n",
       "      <td>$intc</td>\n",
       "      <td>0.796507</td>\n",
       "      <td>0.455341</td>\n",
       "      <td>0.679032</td>\n",
       "      <td>0.354336</td>\n",
       "      <td>-1.799055</td>\n",
       "      <td>0.126153</td>\n",
       "      <td>0.297111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id      date ticker       SF1       SF2       SF3       SF4       SF5  \\\n",
       "0  270007  21/07/18  $INTC -3.062194  1.223466  1.741714  2.279266 -1.323573   \n",
       "1  270008  05/10/18  $CTSH  0.816263 -2.184408  0.157975 -0.264743 -0.836282   \n",
       "2  270009  01/10/18    $CB  0.401281  0.091604  0.083411 -1.147041 -0.485223   \n",
       "3  270010  24/10/18  $CTAS -0.783521  1.192929  0.813831 -0.368166 -1.113656   \n",
       "4  270011  27/07/18  $intc  0.796507  0.455341  0.679032  0.354336 -1.799055   \n",
       "\n",
       "        SF6       SF7  \n",
       "0 -0.274912 -4.504449  \n",
       "1  0.046276  0.826353  \n",
       "2 -0.601060  1.012811  \n",
       "3 -0.553581 -0.683803  \n",
       "4  0.126153  0.297111  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_factors.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jason_data = pd.read_json(\"test_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'stocktwit_tweet': '$CELG nothing to be exite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'stocktwit_tweet': '$AMD yall exhaust your bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'stocktwit_tweet': '$AMD day traders day.', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'stocktwit_tweet': '$CBS https://tenor.com/wL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'stocktwit_tweet': '$MU weak price action so ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             records\n",
       "0  {'stocktwit_tweet': '$CELG nothing to be exite...\n",
       "1  {'stocktwit_tweet': '$AMD yall exhaust your bu...\n",
       "2  {'stocktwit_tweet': '$AMD day traders day.', '...\n",
       "3  {'stocktwit_tweet': '$CBS https://tenor.com/wL...\n",
       "4  {'stocktwit_tweet': '$MU weak price action so ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jason_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter = pd.DataFrame([i for i in jason_data.records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stocktwit_tweet</th>\n",
       "      <th>ticker</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$CELG nothing to be exited about</td>\n",
       "      <td>$CELG</td>\n",
       "      <td>2018-10-25 14:26:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$AMD yall exhaust your buyer on first green ca...</td>\n",
       "      <td>$AMD</td>\n",
       "      <td>2018-07-13 13:50:39+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$AMD day traders day.</td>\n",
       "      <td>$AMD</td>\n",
       "      <td>2018-09-25 19:10:54+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$CBS https://tenor.com/wLB8.gif</td>\n",
       "      <td>$CBS</td>\n",
       "      <td>2018-07-27 22:45:48+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$MU weak price action so far today. Donâ€™t be a...</td>\n",
       "      <td>$MU</td>\n",
       "      <td>2018-07-31 14:59:06+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     stocktwit_tweet ticker  \\\n",
       "0                   $CELG nothing to be exited about  $CELG   \n",
       "1  $AMD yall exhaust your buyer on first green ca...   $AMD   \n",
       "2                              $AMD day traders day.   $AMD   \n",
       "3                    $CBS https://tenor.com/wLB8.gif   $CBS   \n",
       "4  $MU weak price action so far today. Donâ€™t be a...    $MU   \n",
       "\n",
       "                   timestamp  \n",
       "0  2018-10-25 14:26:16+00:00  \n",
       "1  2018-07-13 13:50:39+00:00  \n",
       "2  2018-09-25 19:10:54+00:00  \n",
       "3  2018-07-27 22:45:48+00:00  \n",
       "4  2018-07-31 14:59:06+00:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_twitter.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265022, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_twitter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Timestamp to Date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter['Date']=Test_data_twitter['timestamp'].str.split(expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter['date']=pd.to_datetime(Test_data_twitter['Date'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter.drop('timestamp',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stocktwit_tweet</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$CELG nothing to be exited about</td>\n",
       "      <td>$CELG</td>\n",
       "      <td>2018-10-25</td>\n",
       "      <td>2018-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$AMD yall exhaust your buyer on first green ca...</td>\n",
       "      <td>$AMD</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>2018-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$AMD day traders day.</td>\n",
       "      <td>$AMD</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>2018-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$CBS https://tenor.com/wLB8.gif</td>\n",
       "      <td>$CBS</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>2018-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$MU weak price action so far today. Donâ€™t be a...</td>\n",
       "      <td>$MU</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>2018-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     stocktwit_tweet ticker        Date  \\\n",
       "0                   $CELG nothing to be exited about  $CELG  2018-10-25   \n",
       "1  $AMD yall exhaust your buyer on first green ca...   $AMD  2018-07-13   \n",
       "2                              $AMD day traders day.   $AMD  2018-09-25   \n",
       "3                    $CBS https://tenor.com/wLB8.gif   $CBS  2018-07-27   \n",
       "4  $MU weak price action so far today. Donâ€™t be a...    $MU  2018-07-31   \n",
       "\n",
       "        date  \n",
       "0 2018-10-25  \n",
       "1 2018-07-13  \n",
       "2 2018-09-25  \n",
       "3 2018-07-27  \n",
       "4 2018-07-31  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_twitter.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 265022 entries, 0 to 265021\n",
      "Data columns (total 4 columns):\n",
      "stocktwit_tweet    265022 non-null object\n",
      "ticker             265022 non-null object\n",
      "Date               265022 non-null object\n",
      "date               265022 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "Test_data_twitter.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Duplicate Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6245"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_twitter.duplicated(keep=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261142, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_twitter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_twitter.drop('duplicate',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter =Test_data_twitter.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stocktwit_tweet</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$CELG nothing to be exited about</td>\n",
       "      <td>$CELG</td>\n",
       "      <td>2018-10-25</td>\n",
       "      <td>2018-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$AMD yall exhaust your buyer on first green ca...</td>\n",
       "      <td>$AMD</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>2018-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$AMD day traders day.</td>\n",
       "      <td>$AMD</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>2018-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$CBS https://tenor.com/wLB8.gif</td>\n",
       "      <td>$CBS</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>2018-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$MU weak price action so far today. Donâ€™t be a...</td>\n",
       "      <td>$MU</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>2018-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     stocktwit_tweet ticker        Date  \\\n",
       "0                   $CELG nothing to be exited about  $CELG  2018-10-25   \n",
       "1  $AMD yall exhaust your buyer on first green ca...   $AMD  2018-07-13   \n",
       "2                              $AMD day traders day.   $AMD  2018-09-25   \n",
       "3                    $CBS https://tenor.com/wLB8.gif   $CBS  2018-07-27   \n",
       "4  $MU weak price action so far today. Donâ€™t be a...    $MU  2018-07-31   \n",
       "\n",
       "        date  \n",
       "0 2018-10-25  \n",
       "1 2018-07-13  \n",
       "2 2018-09-25  \n",
       "3 2018-07-27  \n",
       "4 2018-07-31  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_twitter.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping original copy of data before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index(['stocktwit_tweet', 'ticker', 'Date', 'date'], dtype='object')\n",
      "Index(['stocktwit_tweet', 'ticker', 'Date', 'date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(Test_data_twitter['ticker']))\n",
    "original_data = copy.deepcopy(Test_data_twitter)\n",
    "print(Test_data_twitter.keys())\n",
    "print(original_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Expand Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "\n",
    "def expand_contractions(text):\n",
    "    for word in text.split():\n",
    "        if word.lower() in contractions:\n",
    "            text = text.replace(word, contractions[word.lower()])\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Remove Accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    #https://docs.python.org/2/library/unicodedata.html\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to remove scrub words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_words(text):\n",
    "    #Replace \\xao characters in text\n",
    "    text = re.sub('\\xa0', ' ', text)\n",
    "    \n",
    "    #Replace non ascii / not words and digits\n",
    "    text = re.sub(\"(\\\\W|\\\\d)\",' ',text)\n",
    "    \n",
    "    #Replace new line characters and following text untill space\n",
    "    text = re.sub('\\n(\\w*?)[\\s]', '', text)\n",
    "    \n",
    "    #Remove html markup\n",
    "    text = re.sub(\"<.*?>\", ' ', text)\n",
    "    \n",
    "    #Remove extra spaces from the text\n",
    "    text = re.sub(\"\\s+\", ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to clean Twitter related Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_twitter_data(text):\n",
    "    \n",
    "    text= re.sub('http\\S*|www.\\S*','', text) #remove http/https address\n",
    "    text= emoji.demojize(text)  #Convert emoji into text\n",
    "    text= re.sub(\"_\", ' ', text) #remove \"_\" from text\n",
    "    text= text.strip().lower()  #Convert into lower case\n",
    "    text= re.sub(\"@[\\w]*\",\"\", text) #remove @twitter \n",
    "    text= re.sub(\"\\$[\\w]*\",\"\", text) #remove $sign\n",
    "    \n",
    "    text= re.sub(\"[#+]?\\B\",\"\", text) #remove hashtags\n",
    "    #text= re.sub(\"#\",\"\", text)\n",
    "    text= expand_contractions(re.sub('â€™', \"'\", text)) #Expand contractions\n",
    "    text= remove_accented_chars(text) #remove accented characters\n",
    "    text= scrub_words(text) #remove scrub words\n",
    "    return text\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter['stocktwit_tweet']=Test_data_twitter['stocktwit_tweet'].apply(strip_html_tags)\n",
    "\n",
    "Test_data_twitter['stocktwit_tweet']=Test_data_twitter['stocktwit_tweet'].apply(lambda x: cleaning_twitter_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using TextBlob to spell correct.\n",
    "\n",
    "#import textblob\n",
    "#from textblob import TextBlob\n",
    "\n",
    "#data_twitter['stocktwit_tweet'] = [TextBlob(text).correct() for text in data_twitter['stocktwit_tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: \n",
      " $AMD yall exhaust your buyer on first green candle,,,, byeeeeee\n",
      "\n",
      "\n",
      "**************************************************************************\n",
      "\n",
      "\n",
      "Clean data: \n",
      "  yall exhaust your buyer on first green candle byeeeeee\n"
     ]
    }
   ],
   "source": [
    "print(\"Original data: \\n\",original_data['stocktwit_tweet'][1])\n",
    "print(\"\\n\\n**************************************************************************\\n\\n\")\n",
    "print(\"Clean data: \\n\",Test_data_twitter['stocktwit_tweet'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove dollar sign from ticker column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter['ticker']=Test_data_twitter['ticker'].str.replace(\"$\",\"\")\n",
    "Test_data_twitter['ticker']=Test_data_twitter['ticker'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter.to_csv(\"first.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_twitter=pd.read_csv(\"first.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Remove Stop words and stemming the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 326\n",
      "First ten stop words: ['less', 'no', 'becoming', 'before', 'then', 'neither', 'did', 'whereas', 'may', 'amongst']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print('Number of stop words: %d' % len(stopwords))\n",
    "print('First ten stop words: %s' % list(stopwords)[:10])\n",
    "stopwords.remove('no')\n",
    "stopwords.remove('not')\n",
    "stopwords.add('utm');\n",
    "\n",
    "stopwords.add('source');\n",
    "stopwords.add('stocktwits');\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "tokenizer = ToktokTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def stopword_remove_lemma(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    #filtered_tokens = [stemmer.stem(i) for i in filtered_tokens]\n",
    "    filtered_tokens = [lemmatizer.lemmatize(i) for i in filtered_tokens]\n",
    "    filtered_text = ' '.join(filtered_tokens) \n",
    "\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter['stocktwit_tweet']=Test_data_twitter['stocktwit_tweet'].apply(lambda x: stopword_remove_lemma(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: \n",
      " $AMD yall exhaust your buyer on first green candle,,,, byeeeeee\n",
      "\n",
      "\n",
      "**************************************************************************\n",
      "\n",
      "\n",
      "Clean data: \n",
      " yall exhaust buyer green candle byeeeeee\n"
     ]
    }
   ],
   "source": [
    "print(\"Original data: \\n\",original_data['stocktwit_tweet'][1])\n",
    "print(\"\\n\\n**************************************************************************\\n\\n\")\n",
    "print(\"Clean data: \\n\",Test_data_twitter['stocktwit_tweet'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter.to_csv('after_clean_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stocktwit_tweet    0\n",
       "ticker             0\n",
       "Date               0\n",
       "date               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_twitter.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stocktwit_tweet    7447\n",
       "ticker             7447\n",
       "Date               7447\n",
       "date               7447\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_twitter[Test_data_twitter['stocktwit_tweet']==\"\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter=Test_data_twitter[Test_data_twitter['stocktwit_tweet']!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_twitter['stocktwit_tweet'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253695, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_twitter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter.to_csv(\"Test_data_twitter_pre_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of Factors data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11575 entries, 0 to 11574\n",
      "Data columns (total 10 columns):\n",
      "Id        11575 non-null int64\n",
      "date      11575 non-null object\n",
      "ticker    11575 non-null object\n",
      "SF1       11575 non-null float64\n",
      "SF2       11575 non-null float64\n",
      "SF3       11575 non-null float64\n",
      "SF4       11575 non-null float64\n",
      "SF5       11575 non-null float64\n",
      "SF6       11575 non-null float64\n",
      "SF7       11575 non-null float64\n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 904.4+ KB\n"
     ]
    }
   ],
   "source": [
    "Test_data_factors.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_factors['date']=pd.to_datetime(Test_data_factors['date'].astype(str),format=\"%d/%m/%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id        0\n",
       "date      0\n",
       "ticker    0\n",
       "SF1       0\n",
       "SF2       0\n",
       "SF3       0\n",
       "SF4       0\n",
       "SF5       0\n",
       "SF6       0\n",
       "SF7       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_factors.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_factors.duplicated(keep=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove dollar sign from ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_factors['ticker'] = Test_data_factors['ticker'].str.replace(\"$\",\"\")\n",
    "Test_data_factors['ticker']=Test_data_factors['ticker'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>SF1</th>\n",
       "      <th>SF2</th>\n",
       "      <th>SF3</th>\n",
       "      <th>SF4</th>\n",
       "      <th>SF5</th>\n",
       "      <th>SF6</th>\n",
       "      <th>SF7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270007</td>\n",
       "      <td>2018-07-21</td>\n",
       "      <td>INTC</td>\n",
       "      <td>-3.062194</td>\n",
       "      <td>1.223466</td>\n",
       "      <td>1.741714</td>\n",
       "      <td>2.279266</td>\n",
       "      <td>-1.323573</td>\n",
       "      <td>-0.274912</td>\n",
       "      <td>-4.504449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270008</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>CTSH</td>\n",
       "      <td>0.816263</td>\n",
       "      <td>-2.184408</td>\n",
       "      <td>0.157975</td>\n",
       "      <td>-0.264743</td>\n",
       "      <td>-0.836282</td>\n",
       "      <td>0.046276</td>\n",
       "      <td>0.826353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270009</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>CB</td>\n",
       "      <td>0.401281</td>\n",
       "      <td>0.091604</td>\n",
       "      <td>0.083411</td>\n",
       "      <td>-1.147041</td>\n",
       "      <td>-0.485223</td>\n",
       "      <td>-0.601060</td>\n",
       "      <td>1.012811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270010</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>CTAS</td>\n",
       "      <td>-0.783521</td>\n",
       "      <td>1.192929</td>\n",
       "      <td>0.813831</td>\n",
       "      <td>-0.368166</td>\n",
       "      <td>-1.113656</td>\n",
       "      <td>-0.553581</td>\n",
       "      <td>-0.683803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270011</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>INTC</td>\n",
       "      <td>0.796507</td>\n",
       "      <td>0.455341</td>\n",
       "      <td>0.679032</td>\n",
       "      <td>0.354336</td>\n",
       "      <td>-1.799055</td>\n",
       "      <td>0.126153</td>\n",
       "      <td>0.297111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id       date ticker       SF1       SF2       SF3       SF4       SF5  \\\n",
       "0  270007 2018-07-21   INTC -3.062194  1.223466  1.741714  2.279266 -1.323573   \n",
       "1  270008 2018-10-05   CTSH  0.816263 -2.184408  0.157975 -0.264743 -0.836282   \n",
       "2  270009 2018-10-01     CB  0.401281  0.091604  0.083411 -1.147041 -0.485223   \n",
       "3  270010 2018-10-24   CTAS -0.783521  1.192929  0.813831 -0.368166 -1.113656   \n",
       "4  270011 2018-07-27   INTC  0.796507  0.455341  0.679032  0.354336 -1.799055   \n",
       "\n",
       "        SF6       SF7  \n",
       "0 -0.274912 -4.504449  \n",
       "1  0.046276  0.826353  \n",
       "2 -0.601060  1.012811  \n",
       "3 -0.553581 -0.683803  \n",
       "4  0.126153  0.297111  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 253695 entries, 0 to 261141\n",
      "Data columns (total 4 columns):\n",
      "stocktwit_tweet    253695 non-null object\n",
      "ticker             253695 non-null object\n",
      "Date               253695 non-null object\n",
      "date               253695 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "Test_data_twitter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_twitter.to_csv(\"Test_data_twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_factors.to_csv(\"Test_data_factors.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
